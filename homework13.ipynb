{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework13.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOHLNhPMfTY2s4AXOWqkgiw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZiChengHao/Mat-494/blob/main/homework13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuboXX8mdSyk"
      },
      "source": [
        "4.2 Spectral Clustering\n",
        "Here we provide some examples of spectral clustering using scikit learn:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html\n",
        "\n",
        "Copyright:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46tqam2vdP33",
        "outputId": "95a7e574-cb49-42f1-e4f8-3fcd43ed77bd"
      },
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "from itertools import cycle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-aZ_SI1dXm2"
      },
      "source": [
        "1. From Laplacian to Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjllaKt-dZJ8"
      },
      "source": [
        "# Computes the symetric normalized laplacian\n",
        "# L = D^{-1/2} A D{-1/2}\n",
        "def laplacian(A):\n",
        "    D = numpy.zeros(A.shape)\n",
        "    w = numpy.sum(A, axis=0)\n",
        "    D.flat[::len(w) + 1] = w ** (-0.5)  # set the diag of D to w\n",
        "    return D.dot(A).dot(D)\n",
        "\n",
        "def k_means(X, n_clusters):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=1231)\n",
        "    return kmeans.fit(X).labels_\n",
        "\n",
        "def spectral_clustering(affinity, n_clusters, cluster_method=k_means):\n",
        "    L = laplacian(affinity)\n",
        "    eig_val, eig_vect = scipy.sparse.linalg.eigs(L, n_clusters)\n",
        "    X = eig_vect.real\n",
        "    rows_norm = numpy.linalg.norm(X, axis=1, ord=2)\n",
        "    Y = (X.T / rows_norm).T\n",
        "    labels = cluster_method(Y, n_clusters)\n",
        "    return labels"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j3_nNlHdamo"
      },
      "source": [
        "2. Use sklearn Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "RD1WTT8zdcQ_",
        "outputId": "fc5fd61b-4a93-47ae-dfde-e5fdaf7011fc"
      },
      "source": [
        "# Center for generating random data.\n",
        "centers = [[1, 1], [-1, -1], [1, -1]]\n",
        "\n",
        "# The number of data generated.\n",
        "n_samples=3000\n",
        "\n",
        "# Generate data.\n",
        "X, lables_true = make_blobs(n_samples=n_samples, centers= centers, cluster_std=0.6, \n",
        "                  random_state =0)\n",
        " \n",
        "# Transform to a matrix, the input has to be symmetric.\n",
        "metrics_metrix = (-1 * metrics.pairwise.pairwise_distances(X)).astype(np.int32)\n",
        "metrics_metrix += -1 * metrics_metrix.min()\n",
        "\n",
        "# Set spectral clustering function.\n",
        "n_clusters_= 4\n",
        "lables = spectral_clustering(metrics_metrix,n_clusters=n_clusters_)\n",
        "\n",
        "# Visualization of results\n",
        "plt.figure(1)\n",
        "plt.clf()\n",
        "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
        "for k, col in zip(range(n_clusters_), colors):\n",
        "    # Reassembles an array of True and False based on whether the values in lables are equal to k.\n",
        "    my_members = lables == k\n",
        "    plt.plot(X[my_members, 0], X[my_members, 1], col + '.')\n",
        "    \n",
        "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-137213633285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Set spectral clustering function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mn_clusters_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mlables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectral_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_metrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_clusters_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Visualization of results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-60d8c6f07211>\u001b[0m in \u001b[0;36mspectral_clustering\u001b[0;34m(affinity, n_clusters, cluster_method)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspectral_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maffinity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaplacian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maffinity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0meig_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meig_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meig_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-60d8c6f07211>\u001b[0m in \u001b[0;36mlaplacian\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# L = D^{-1/2} A D{-1/2}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlaplacian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# set the diag of D to w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwAk__Wpddee"
      },
      "source": [
        "3. Kaggle Credit Card Dataset\n",
        "Please download the dataset firs: https://www.kaggle.com/arjunbhasin2013/ccdata\n",
        "\n",
        "Before loading the data, please change the file name to avoid blanks, and put it under the working path.\n",
        "\n",
        "3.1 Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQlteb4wde2Q"
      },
      "source": [
        "# Load the data via relative path\n",
        "X = pd.read_csv('../textbook/CC_GENERAL.csv')\n",
        "  \n",
        "# Dropping the CUST_ID column from the data\n",
        "X = X.drop('CUST_ID', axis = 1)\n",
        "  \n",
        "# Handling the missing values if any\n",
        "X.fillna(method ='ffill', inplace = True)\n",
        "  \n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Orv7eZ6NdgC7"
      },
      "source": [
        "# Preprocessing the data to make it visualizable\n",
        "\n",
        "# Scaling the Data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Normalizing the Data\n",
        "X_normalized = normalize(X_scaled)\n",
        "\n",
        "# Converting the numpy array into a pandas DataFrame\n",
        "X_normalized = pd.DataFrame(X_normalized)\n",
        "\n",
        "# Reducing the dimensions of the data\n",
        "pca = PCA(n_components = 2)\n",
        "X_principal = pca.fit_transform(X_normalized)\n",
        "X_principal = pd.DataFrame(X_principal)\n",
        "X_principal.columns = ['P1', 'P2']\n",
        "\n",
        "X_principal.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od3rtsYgdhDZ"
      },
      "source": [
        "3.2 Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPEU1hb3diWR"
      },
      "source": [
        "# Building the clustering model\n",
        "spectral_model_rbf = SpectralClustering(n_clusters = 2, affinity ='rbf')\n",
        "\n",
        "# Training the model and Storing the predicted cluster labels\n",
        "labels_rbf = spectral_model_rbf.fit_predict(X_principal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf3FQ8UrdjRy"
      },
      "source": [
        "(1) affinity = ‘rbf’"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCymtLxqdk-l"
      },
      "source": [
        "# Building the label to colour mapping\n",
        "colours = {}\n",
        "colours[0] = 'b'\n",
        "colours[1] = 'y'\n",
        "\n",
        "# Building the colour vector for each data point\n",
        "cvec = [colours[label] for label in labels_rbf]\n",
        "\n",
        "# Plotting the clustered scatter plot\n",
        "\n",
        "b = plt.scatter(X_principal['P1'], X_principal['P2'], color ='b');\n",
        "y = plt.scatter(X_principal['P1'], X_principal['P2'], color ='y');\n",
        "\n",
        "plt.figure(figsize =(9, 9))\n",
        "plt.scatter(X_principal['P1'], X_principal['P2'], c = cvec)\n",
        "plt.legend((b, y), ('Label 0', 'Label 1'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCVD8p-YdnAn"
      },
      "source": [
        "(2) affinity = ‘nearest_neighbors’"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq4et-PCdo8h"
      },
      "source": [
        "# Building the clustering model\n",
        "spectral_model_nn = SpectralClustering(n_clusters = 2, affinity ='nearest_neighbors')\n",
        "\n",
        "# Training the model and Storing the predicted cluster labels\n",
        "labels_nn = spectral_model_nn.fit_predict(X_principal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmcXHjEhdp8j"
      },
      "source": [
        "3.3 Evaluate the Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7X5bBuZdrIq"
      },
      "source": [
        "# List of different values of affinity\n",
        "affinity = ['rbf', 'nearest-neighbours']\n",
        "\n",
        "# List of Silhouette Scores\n",
        "s_scores = []\n",
        "\n",
        "# Evaluating the performance\n",
        "s_scores.append(silhouette_score(X, labels_rbf))\n",
        "s_scores.append(silhouette_score(X, labels_nn))\n",
        "\n",
        "print(s_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1uYN8uadsEq"
      },
      "source": [
        "# Plotting a Bar Graph to compare the models\n",
        "plt.bar(affinity, s_scores)\n",
        "plt.xlabel('Affinity')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Comparison of different Clustering Models')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}